{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "давно известно маркетолог использовать различный приём воздействие клиент владельцысупермаркет знать этот приём невозможно обойтись поэтому стараться можно чаща применятий практика автор рассматриваться основной приём воздействие потенциальный клиент супер маркета супермаркет маркетинг товар покупка метод воздействие маркетинговый приём\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import _pickle as cPickle\n",
    "#Загрузка даных:\n",
    "file = open(\"file.txt\", 'rb')\n",
    "df = cPickle.load(file)\n",
    "file.close()\n",
    "i=230\n",
    "print(df.data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция чистки текста:\n",
    "import pymorphy2\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    text = text.replace(\"\\\\\", \" \").replace(u\"╚\", \" \").replace(u\"╩\", \" \")\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\-\\s\\r\\n\\s{1,}|\\-\\s\\r\\n|\\r\\n', '', text) #deleting newlines and line-breaks\n",
    "    text = re.sub('[.,:;_%©?*,!@#$%^&()\\d]|[+=]|[[]|[]]|[/]|\"|\\s{2,}|-', ' ', text) #deleting symbols  \n",
    "    text = ' '.join(word for word in text.split() if len(word)>3)\n",
    "    text = \" \".join(morph.parse(word)[0].normal_form for word in text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальное количество слов в самом длинном описании заявки: 119 слов\n"
     ]
    }
   ],
   "source": [
    "# Максимальное количество слов в самом длинном описании заявки\n",
    "max_words = 0\n",
    "for desc in df.data[0:i+1]:\n",
    "    words = len(desc.split())\n",
    "    if words > max_words:\n",
    "        max_words = words\n",
    "print('Максимальное количество слов в самом длинном описании заявки: {} слов'.format(max_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего слов в словаре:  3731\n",
      "Распределение по рубликам:  [13. 39. 25. 23.  6.  6. 19. 10. 22.  7.  4.  6.  2. 18.  6.  5.  6.  1.\n",
      "  3.  8.  2.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "#Составление словаря\n",
    "vocab = Counter()\n",
    "newsgroups_train=df\n",
    "for text in newsgroups_train.data[0:i+1]:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()]=1\n",
    "        \n",
    "total_words = len(vocab)\n",
    "print('Всего слов в словаре: ', total_words)\n",
    "#Функция, которая возвращает индекс слова в словаре\n",
    "def get_word_2_index(vocab):\n",
    "    word2index = {}\n",
    "    for i,word in enumerate(vocab):\n",
    "        word2index[word.lower()] = i\n",
    "        \n",
    "    return word2index\n",
    "\n",
    "word2index = get_word_2_index(vocab)\n",
    "\n",
    "#Составление числовых векторов\n",
    "batches = []\n",
    "results = []\n",
    "texts = newsgroups_train.data[0:i+1]\n",
    "categories = newsgroups_train.target[0:i+1]\n",
    "\n",
    "for text in texts:\n",
    "   k=0\n",
    "   layer = np.zeros(max_words,dtype=float)\n",
    "   for word in text.split(' '):\n",
    "        if (vocab[word.lower()])!=0:\n",
    "          layer[k] = word2index[word.lower()]\n",
    "          k+=1\n",
    "            \n",
    "   batches.append(layer)\n",
    "X_train=np.array(batches)\n",
    "\n",
    "\n",
    "y=0\n",
    "num_classes=21\n",
    "target=np.zeros((num_classes))\n",
    "y_train=np.zeros((i+1,num_classes))\n",
    "for у in range(i+1):\n",
    "    y_train[y,df.target[y]-1]=1\n",
    "    target[df.target[y]-1]+=1\n",
    "    y+=1    \n",
    "\n",
    "print('Распределение по рубликам: ',target)\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность обучающей выборки:  (216, 119)\n",
      "Размерность тестовой выборки:  (15, 119)\n"
     ]
    }
   ],
   "source": [
    "#Разбиение на обучающую и тестовую выборку\n",
    "n=15\n",
    "X_test=X_train[i+1-n:i+1] \n",
    "y_test=y_train[i+1-n:i+1]\n",
    "y_train=y_train[0:i+1-n]\n",
    "X_train=X_train[0:i+1-n]\n",
    "print('Размерность обучающей выборки: ',X_train.shape)\n",
    "print('Размерность тестовой выборки: ',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собираем модель...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, 119, 32)           119392    \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 21)                1365      \n",
      "=================================================================\n",
      "Total params: 145,589\n",
      "Trainable params: 145,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "#Реккурентная модель\n",
    "# максимальное количество слов для анализа\n",
    "max_features = total_words\n",
    "\n",
    "print(u'Собираем модель...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, embedding_vecor_length, input_length=max_words))\n",
    "model.add(LSTM(100)\n",
    "model.add(Dense(num_classes, activation='softmax'))#'sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собираем модель...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_25 (Embedding)     (None, 119, 32)           119392    \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 119, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 59, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 59, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 59, 32)            4128      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 29, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 29, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 200)               186400    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 21)                4221      \n",
      "=================================================================\n",
      "Total params: 317,245\n",
      "Trainable params: 317,245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout,Conv1D,MaxPooling1D\n",
    "#Сверточная модель\n",
    "# максимальное количество слов для анализа\n",
    "max_features = total_words\n",
    "\n",
    "print(u'Собираем модель...')\n",
    "model = Sequential()\n",
    "embedding_vecor_length = 32\n",
    "model.add(Embedding(total_words, embedding_vecor_length, input_length=max_words))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(LSTM(200,dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "   \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренируем модель...\n",
      "Train on 216 samples, validate on 15 samples\n",
      "Epoch 1/30\n",
      "216/216 [==============================] - 152s 705ms/step - loss: 3.0354 - acc: 0.1065 - val_loss: 3.0182 - val_acc: 0.0667\n",
      "Epoch 2/30\n",
      "216/216 [==============================] - 2s 9ms/step - loss: 2.9815 - acc: 0.1759 - val_loss: 2.9131 - val_acc: 0.0667\n",
      "Epoch 3/30\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2.8242 - acc: 0.1759 - val_loss: 2.8061 - val_acc: 0.0667\n",
      "Epoch 4/30\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 2.7461 - acc: 0.1759 - val_loss: 2.7440 - val_acc: 0.0667\n",
      "Epoch 5/30\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2.7514 - acc: 0.1250 - val_loss: 2.7445 - val_acc: 0.1333\n",
      "Epoch 6/30\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2.7257 - acc: 0.1481 - val_loss: 2.7575 - val_acc: 0.0667\n",
      "Epoch 7/30\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2.7093 - acc: 0.1759 - val_loss: 2.8226 - val_acc: 0.0667\n",
      "Epoch 8/30\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2.7097 - acc: 0.1759 - val_loss: 2.8504 - val_acc: 0.0667\n",
      "Epoch 9/30\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2.7230 - acc: 0.1759 - val_loss: 2.8490 - val_acc: 0.0667\n",
      "Epoch 10/30\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2.6927 - acc: 0.1759 - val_loss: 2.8681 - val_acc: 0.0667\n",
      "Epoch 11/30\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2.6899 - acc: 0.1759 - val_loss: 2.8698 - val_acc: 0.0667\n",
      "Epoch 12/30\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2.6911 - acc: 0.1759 - val_loss: 2.8079 - val_acc: 0.0667\n",
      "Epoch 13/30\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2.6407 - acc: 0.1759 - val_loss: 2.8103 - val_acc: 0.0667\n",
      "Epoch 14/30\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2.5873 - acc: 0.1759 - val_loss: 2.7864 - val_acc: 0.0667\n",
      "Epoch 15/30\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2.5155 - acc: 0.1759 - val_loss: 2.6967 - val_acc: 0.0667\n",
      "Epoch 16/30\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2.3699 - acc: 0.1806 - val_loss: 2.7465 - val_acc: 0.0667\n",
      "Epoch 17/30\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 2.2984 - acc: 0.1806 - val_loss: 3.0504 - val_acc: 0.0667\n",
      "Epoch 18/30\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 2.2903 - acc: 0.1806 - val_loss: 3.0971 - val_acc: 0.0667\n",
      "Epoch 19/30\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2.2694 - acc: 0.1806 - val_loss: 3.1439 - val_acc: 0.1333\n",
      "Epoch 20/30\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2.2438 - acc: 0.1806 - val_loss: 3.1172 - val_acc: 0.1333\n",
      "Epoch 21/30\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 2.2278 - acc: 0.1898 - val_loss: 3.2013 - val_acc: 0.1333\n",
      "Epoch 22/30\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 2.2010 - acc: 0.2407 - val_loss: 3.2393 - val_acc: 0.1333\n",
      "Epoch 23/30\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2.1812 - acc: 0.2222 - val_loss: 3.2625 - val_acc: 0.1333\n",
      "Epoch 24/30\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 2.1655 - acc: 0.2222 - val_loss: 3.0033 - val_acc: 0.1333\n",
      "Epoch 25/30\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 2.0977 - acc: 0.2546 - val_loss: 2.9031 - val_acc: 0.0667\n",
      "Epoch 26/30\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 2.0855 - acc: 0.2269 - val_loss: 2.8941 - val_acc: 0.0000e+00\n",
      "Epoch 27/30\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 1.9620 - acc: 0.2639 - val_loss: 2.9332 - val_acc: 0.0000e+00\n",
      "Epoch 28/30\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 1.8713 - acc: 0.2917 - val_loss: 2.8838 - val_acc: 0.0000e+00\n",
      "Epoch 29/30\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 1.8205 - acc: 0.2870 - val_loss: 2.9533 - val_acc: 0.0000e+00\n",
      "Epoch 30/30\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 1.7486 - acc: 0.3009 - val_loss: 3.1614 - val_acc: 0.1333\n"
     ]
    }
   ],
   "source": [
    "#Обучение модели\n",
    "batch_size = 64\n",
    "epochs = 30\n",
    "\n",
    "print(u'Тренируем модель...')\n",
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step\n",
      "\n",
      "Оценка теста: 3.161428213119507\n",
      "Оценка точности модели: 0.13333334028720856\n"
     ]
    }
   ],
   "source": [
    "#Оценка модели\n",
    "score = model.evaluate(X_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print()\n",
    "print(u'Оценка теста: {}'.format(score[0]))\n",
    "print(u'Оценка точности модели: {}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Получение прогноза от модели\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    " \n",
    "j=0\n",
    "for j in range(15):\n",
    "    print('Правильная категория: ',np.argmax(y_test[j])+1)\n",
    "    print(\"Определенная моделью категория: \",np.argmax(prediction[j])+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
